{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91373ca-d59a-4b91-84e6-640d84f79acf",
   "metadata": {},
   "source": [
    "# Content-Based Movie Recommendation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ddf64c6",
   "metadata": {},
   "source": [
    "This notebook employs Natural Language processing in order to recommend movies to users based on its content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae862d91-90d1-409b-a2f9-d583cb6ce855",
   "metadata": {},
   "source": [
    "Dataset Source:\n",
    "\n",
    "https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7e171-0fdb-4ddf-85ff-f27c9bb9a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0a147-7e04-48de-936f-d3ab65199335",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b539ffb",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae41f0b-e3f8-498c-bd1c-b2f25df70207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\14385\\\\Desktop\\\\GitHub Projects\\\\wiki_movie_plots_deduped.csv\")\n",
    "#\"C:\\Users\\14385\\Desktop\\GitHub Projects\\wiki_movie_plots_deduped.csv\"\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa74f37-569c-4020-8618-2ca36f0ea638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1170db1-bbc1-491e-bb14-749497a1c833",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734e382-9716-42c7-bc4b-5db5f3686602",
   "metadata": {},
   "source": [
    "### Converting to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926ee34-27f7-48d3-bc6d-c0bb1e64086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb3056-c353-4e45-a921-0e5d07966b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df66a9-46c8-4a33-9775-b1d8d83636a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6c020-a144-4c1c-b2aa-404c9e7f7988",
   "metadata": {},
   "source": [
    "Action Items:\n",
    "\n",
    "* Lower-Case the whole data frame\n",
    "* Director: Removing 'Director:' and 'Cast:'\n",
    "* Director, Cast: Removing '\\r\\n', '\\n' and '\\r'\n",
    "\n",
    "* Genre: Replacing '/' with Space\n",
    "* Director, Cast, Genre: Removing 'Uknonwn' and 'Nan'\n",
    "\n",
    "* Director: Separating Directors and Actors names\n",
    "* Director, Cast: Checking if the names are separated with ' and ', ' & '\n",
    "\n",
    "* Director, Cast: Merging the first names and last names together\n",
    "* Director, Cast: Adding the words of 'Director' and 'Actor' as prefix\n",
    "\n",
    "* Plot: Removing English Stopwords\n",
    "* Doc: Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690e769-0628-4299-8d78-906500e9d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ee1b5-efaa-446a-b0e8-e5cefcd501e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Director\"] = df[\"Director\"].str.replace(\"director:\", \"\", regex=False)\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\"cast:\", \"\", regex=False)\n",
    "\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\"\\r\\n\", \" \", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\"\\r\\n\", \" \", regex=False)\n",
    "\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\"\\n\", \" \", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\"\\n\", \" \", regex=False)\n",
    "\n",
    "df[\"Genre\"] = df[\"Genre\"].str.replace(\"/\", \" \", regex=False)\n",
    "\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\"unknown\", \"\", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\"unknown\", \"\", regex=False)\n",
    "df[\"Genre\"] = df[\"Genre\"].str.replace(\"unknown\", \"\", regex=False)\n",
    "\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\"nan\", \"\", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\"nan\", \"\", regex=False)\n",
    "df[\"Genre\"] = df[\"Genre\"].str.replace(\"nan\", \"\", regex=False)\n",
    "\n",
    "\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\" and \", \",\", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\" and \", \",\", regex=False)\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\" & \", \",\", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\" & \", \",\", regex=False)\n",
    "\n",
    "\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\" \", \"\", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\" \", \"\", regex=False)\n",
    "\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\",\", \" \", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\",\", \" \", regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f2e8d-6090-4b46-8327-29ec746f2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Director\"] = np.where(df[\"Director\"].str.len() > 0,\n",
    "                          'director' + df[\"Director\"],\n",
    "                          df[\"Director\"])\n",
    "\n",
    "df[\"Cast\"] = np.where(df[\"Cast\"].str.len() > 0,\n",
    "                      'actor' + df[\"Cast\"],\n",
    "                      df[\"Cast\"])\n",
    "\n",
    "df[\"Director\"] = df[\"Director\"].str.replace(\" \", \" director\", regex=False)\n",
    "df[\"Cast\"] = df[\"Cast\"].str.replace(\" \", \" actor\", regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648aae3-5778-4c50-9882-6acfe1c0f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977c0c2-09e5-4395-9da1-bc153293c3ed",
   "metadata": {},
   "source": [
    "### Merging the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27e6e2-0d3b-436f-9baa-f8375a828ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_weights = {\"Release Year\": 10,\n",
    "                  \"Title\": 1,\n",
    "                  \"Origin/Ethnicity\": 5,\n",
    "                  \"Director\": 5,\n",
    "                  \"Cast\": 1,\n",
    "                  \"Genre\": 10,\n",
    "                  \"Plot\": 1}\n",
    "\n",
    "df[\"doc\"] = \"\"\n",
    "\n",
    "for col in column_weights.keys():\n",
    "    df[\"doc\"] += column_weights[col] * (df[col] + ' ')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47c682f3-f42c-40df-9a0b-0d1d5dce04c6",
   "metadata": {},
   "source": [
    "df[\"doc\"] = df[['Release Year', 'Title', 'Origin/Ethnicity',\n",
    "                'Director', 'Cast', 'Genre', 'Plot']].agg(' '.join, axis=1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3220bd8-ddaa-4702-a67a-a3609aea57c6",
   "metadata": {},
   "source": [
    "### Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6f2dc-5a1b-433d-a059-5e16abae7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"doc\"] = df[\"doc\"].str.replace(\"[^a-z 0-9]+\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcea218-b3b0-4696-a144-899e11578b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df[[\"doc\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd1b224-4302-413c-8be2-eeb86ae9a2c6",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19bf29d9-ee7a-45ed-a533-14c2a1ddb8ed",
   "metadata": {},
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43928d-9dd7-4702-b3c5-1aed384a0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d960a0a-139c-4f65-9529-1e679a6eeab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fbe02f0",
   "metadata": {},
   "source": [
    "This part of the code might not run in all the machines due to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0830e4-89c9-4ae9-b3ba-c6f4e8ce1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(sentence):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "df['doc_clean'] = df['doc'].map(lambda s:preprocess(s)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fe0f51",
   "metadata": {},
   "source": [
    "Lemmatization aims to convert different inflected forms of a word into a single form to facilitate analysis and comparison. For example, the lemmatized form of \"running\" is \"run\", and the lemmatized form of \"mice\" is \"mouse\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d42fc",
   "metadata": {},
   "source": [
    "Stemming is a simpler proess compared to lemmatization. It involves removing suffixes from words to achieve the root form. Stemming can be less accurate than lemmatization but is often faster and sufficient for certain applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5b40c-d749-4a24-8189-e1f5519ec079",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[[\"doc\", 'doc_clean']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac11761-8447-4a24-9e3d-d673ef19f2c8",
   "metadata": {},
   "source": [
    "## TF-IDF : Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656257b-8df7-4508-9ae7-0e7becbca30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"doc_clean\"])\n",
    "column_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "df_tf_idf = pd.DataFrame(X.toarray(), columns=column_names)\n",
    "df_tf_idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1eb5ca-a539-42a5-bbcd-4ab0df69de5b",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a545449-8f59-4522-9d94-7b0a3210efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df_cos_sim = pd.DataFrame(cosine_similarity(df_tf_idf, dense_output=True))\n",
    "df_cos_sim.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b428317c-96c9-4db5-a4cd-eec739eb5e3d",
   "metadata": {},
   "source": [
    "# saving cosine similarity matrix\n",
    "\n",
    "df_cos_sim.to_parquet(\"../data/movie_cos_sim.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3038a-b659-44d6-972c-99eb7574ced2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Converting Cosine Similarity Dataframe to Top-K Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a48eb8c-c68c-4a12-9a80-700ea1c45837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# hide pandas warning messages\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed3b90-7e89-4de3-84e1-6765015555f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "K = 10\n",
    "\n",
    "df_top_k = pd.DataFrame()\n",
    "movie_indices = df_cos_sim.columns\n",
    "\n",
    "for col in tqdm(movie_indices):\n",
    "    df_test = df_cos_sim[[col]].sort_values(by=[col], ascending=False).head(K+1).copy()\n",
    "\n",
    "    record = []\n",
    "    for index, row in df_test.iterrows():\n",
    "        if index != col:\n",
    "            item = [int(index), float(row[col])]\n",
    "            record.append(item)\n",
    "        if len(record) == K:\n",
    "            break\n",
    "\n",
    "    df_top_k[col] = record\n",
    "\n",
    "df_top_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1002f-45e3-4af4-8263-7f50a5589b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose\n",
    "df_top_k = df_top_k.T\n",
    "\n",
    "df_top_k.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95422e00-2b1a-46fe-ad41-a33792259466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving similarity top-k dataframe\n",
    "\n",
    "df_top_k.to_parquet(\"../data/movie_top_k_t.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7f140-d70c-420d-9f3c-1390bb467ea7",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc83463-efec-4b60-8dd4-43eca0a14764",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291ceb0-8ee9-4c0f-bda2-9ec44990928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'titanic'\n",
    "\n",
    "df[df[\"Title\"].str.contains(\"titanic\")]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11fd01aa",
   "metadata": {},
   "source": [
    "Based on certain movie, in this case Titanic, we are going to see which are the similar movies based on Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd3200-b491-4f98-b8d5-284291427db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_index = 13153 # Titanic Movie\n",
    "\n",
    "df_query = df_cos_sim[[movie_index]].sort_values(by=[movie_index]).tail(5)\n",
    "df_query.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "686c7356",
   "metadata": {},
   "source": [
    "These are the most similar movies, as it gets to zero, it means that the similarity is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab62b4-7f42-4254-89e1-0f46113ee65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad2b1c-8a61-4275-857c-a2fc35d714c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.index == 6275]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371f7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
